ğŸ§  Smart Content Moderator API

A FastAPI-based AI service that analyzes user-submitted content for inappropriate material.

ğŸ“˜ Overview

The Smart Content Moderator API is a backend service built with FastAPI that detects and classifies inappropriate or harmful content (text or images).
It uses OpenAI GPT models for text moderation, stores results in a SQLite database, and provides user-specific moderation analytics.

ğŸ”¹ This version includes core functionality up to result storage.
(Notification and Docker modules are optional extensions.)

ğŸš€ Features

Analyze text or image URLs for toxicity, spam, or harassment

Store all moderation results and request logs in a SQLite database

Retrieve moderation summaries by user email

Built using FastAPI + SQLAlchemy (async)

Extensible for email/Slack notifications (future scope)

ğŸ—ï¸ Tech Stack
Component	Technology Used
Framework	FastAPI (Python 3.9+)
Database	SQLite (via SQLAlchemy ORM)
AI Model	OpenAI GPT-4 / GPT-3.5
Environment	Virtualenv / Conda
Server	Uvicorn (ASGI)
ğŸ“‚ Project Structure
Content_Mod/
â”‚
â”œâ”€â”€ main.py                 # Main FastAPI application
â”œâ”€â”€ database.py             # DB setup and models
â”œâ”€â”€ models.py               # SQLAlchemy ORM models
â”œâ”€â”€ schemas.py              # Pydantic request/response models
â”œâ”€â”€ requirements.txt        # Dependencies list
â”œâ”€â”€ .env                    # Environment variables (API keys)
â””â”€â”€ README.md               # Project documentation

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the Repository
git clone https://github.com/<your-username>/Content_Mod.git
cd Content_Mod

2ï¸âƒ£ Create Virtual Environment

Using venv:

python -m venv venv
venv\Scripts\activate   # on Windows
source venv/bin/activate   # on macOS/Linux


Or using conda:

conda create -n content_mod python=3.10 -y
conda activate content_mod

This one worked for me as I am working on conda.

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set Environment Variables

Create a .env file in your project root:

OPENAI_API_KEY=your_openai_api_key_here

5ï¸âƒ£ Initialize Database
python
>>> from database import init_db
>>> init_db()
>>> exit()


This creates a moderation.db SQLite file.

6ï¸âƒ£ Run the Server
uvicorn main:app --reload


Now visit: ğŸ‘‰ http://127.0.0.1:8000/docs

Youâ€™ll see the Swagger UI for testing your endpoints.

ğŸ§© API Documentation
ğŸ”¹ 1. POST /api/v1/moderate/text

Description: Analyze user text for inappropriate or harmful content.

Request Body:

{
  "email": "user@example.com",
  "text": "You are an idiot"
}


Response:

{
  "classification": "toxic",
  "confidence": 0.92,
  "reasoning": "Contains insult and abusive language."
}

ğŸ”¹ 2. POST /api/v1/moderate/image

Description: Analyze an image (via URL) for explicit or inappropriate content.

Request Body:

{
  "email": "user@example.com",
  "image_url": "https://example.com/image.jpg"
}


Response:

{
  "classification": "safe",
  "confidence": 0.88,
  "reasoning": "No explicit content detected."
}

ğŸ”¹ 3. GET /api/v1/analytics/summary?user=user@example.com

Description: Get the moderation summary for a specific user.

Response:

{
  "total_requests": 10,
  "toxic": 3,
  "safe": 6,
  "spam": 1
}

ğŸ§  How It Works

User sends text/image via API request.

The content is sent to OpenAI GPT for classification.

The model returns a classification and confidence score.

The results are stored in the SQLite database.

(Optional) Notifications can be sent via Slack or email when toxic content is detected.

ğŸ§© Database Schema
moderation_requests
Column	Type	Description
id	Integer	Primary key
content_type	String	'text' or 'image'
content_hash	String	Unique hash of content
status	String	'processed', 'pending'
created_at	DateTime	Timestamp
moderation_results
Column	Type	Description
id	Integer	Primary key
request_id	ForeignKey	Links to moderation_requests
classification	String	Category (toxic/spam/safe)
confidence	Float	Confidence score
reasoning	Text	LLM explanation
llm_response	JSON	Raw model output
ğŸ§° Future Enhancements

ğŸ”” Slack/Email alerts for flagged content

ğŸ³ Docker Compose setup (FastAPI + Postgres)

ğŸ“Š Detailed analytics dashboard

âš™ï¸ Celery-based async background tasks

ğŸ§‘â€ğŸ’» Author

Harshit Kashyap
Final Year B.Tech CSE (AIML) â€” UPES Dehradun
ğŸ“§ harshitkashyap@example.com
